version: "3.9"

services:
  # ─────────────────────── Bases y mensajería ──────────────────────
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: cvflow
      POSTGRES_PASSWORD: cvflow
      POSTGRES_DB: cvflow
    ports: ["5432:5432"]
    volumes: ["pgdata:/var/lib/postgresql/data"]

  rabbitmq:
    image: rabbitmq:3-management
    ports: ["5672:5672", "15672:15672"]
    environment:
      RABBITMQ_DEFAULT_USER: cvflow
      RABBITMQ_DEFAULT_PASS: cvflow

    # ─────────────────────────── Seguridad ───────────────────────────
  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    command: start-dev
    environment:
        # credenciales de administración
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KEYCLOAK_ADMIN_EMAIL: admin@dummy.local

        # --------  URL pública  -----------
      KC_HOSTNAME: keycloak.smartcareermate.kevinhub.dev
      KC_HTTP_RELATIVE_PATH: /auth
      KC_PROXY: edge
      KC_HOSTNAME_STRICT: "false"
      KC_HOSTNAME_STRICT_HTTPS: "true"
    ports:
      - "8180:8080"
    volumes:
      - keycloak_data:/opt/keycloak/data

  mailhog:
    image: mailhog/mailhog:latest
    ports:
      - "1025:1025"
      - "8025:8025"

  # ─────────────────────────── IA / backend ─────────────────────────
  ollama:
    build:
      context: .
      dockerfile: ai-ollama.Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama 

  core-service:
    build: { context: ./core-service }
    depends_on: [postgres, rabbitmq]
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/cvflow
      SPRING_DATASOURCE_USERNAME: cvflow
      SPRING_DATASOURCE_PASSWORD: cvflow
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_USERNAME: cvflow
      SPRING_RABBITMQ_PASSWORD: cvflow
    ports: ["8082:8082"]

  ai-service:
    build: { context: ./ai-service }
    depends_on:
      - ollama
      - rabbitmq
    environment:
      SPRING_AI_OLLAMA_URL: http://ollama:11434
      SPRING_AI_OLLAMA_MODEL: llama3:8b-text-q3_K_S
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_USERNAME: cvflow
      SPRING_RABBITMQ_PASSWORD: cvflow
    ports: ["8084:8083"]

  # ────────────────────────── CV-parser ────────────────────────────
  cv-parser:
    build: { context: ./cv-parser }
    depends_on: [rabbitmq]
    environment:
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_USERNAME: cvflow
      SPRING_RABBITMQ_PASSWORD: cvflow
    ports: ["8085:8085"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/actuator/health"]
      interval: 10s
      timeout: 3s
      retries: 5
  # ──────────────────────────── Frontend ───────────────────────────
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      - gateway
    ports:
      - "4200:80"

  # ─────────────────────────── Gateway ─────────────────────────────
  gateway:
    build: { context: ./gateway }
    depends_on:
      ai-service: { condition: service_started }
      core-service: { condition: service_started }
      cv-parser: { condition: service_healthy }
    environment:
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_USERNAME: cvflow
      SPRING_RABBITMQ_PASSWORD: cvflow
    ports: ["8080:8080"]

volumes:
  pgdata:
  keycloak_data:
  ollama_data: {}
